[worldserver]

###################################################################################################
# LLM CHAT SYSTEM
###################################################################################################

#    LLMChat.Enable
#        Description: Enable the LLM Chat module
#        Default:     1  - (Enabled)
#                     0  - (Disabled)

LLMChat.Enable = 1

#    LLMChat.Announce
#        Description: Announce the module on player login
#        Default:     0  - (Disabled to maintain immersion)
#                     1  - (Enabled)

LLMChat.Announce = 1

#    LLMChat.Provider
#        Description: Which LLM provider to use
#        Default:     1  - (Ollama)
#                     2  - (LM Studio)

LLMChat.Provider = 1

#    LLMChat.Ollama.Endpoint
#        Description: Endpoint URL for Ollama API
#        Default:    "http://localhost:11434/api/generate"

LLMChat.Ollama.Endpoint = "http://localhost:11434/api/generate"

#    LLMChat.Ollama.Model
#        Description: Model to use with Ollama
#        Default:    "llama3.2:1b"

LLMChat.Ollama.Model = "llama3.2:1b"

#    LLMChat.ChatRange
#        Description: Range in yards for chat responses to be visible
#        Default:     25.0

LLMChat.ChatRange = 25.0

#    LLMChat.ResponsePrefix
#        Description: Prefix for responses (empty for natural chat)
#        Default:    ""

LLMChat.ResponsePrefix = "[AI] "

#    LLMChat.LogLevel
#        Description: Level of logging detail
#        Default:     3  - (Detailed)
#                     0  - (Disabled)
#                     1  - (Errors Only)
#                     2  - (Basic)

LLMChat.LogLevel = 3

#    LLMChat.MaxResponsesPerMessage
#        Description: Maximum number of bots that can respond to a single message
#        Default:     2  - (Two bots maximum)
#                     0  - (Disabled)
#                     1-10  - (Number of responding bots)

LLMChat.MaxResponsesPerMessage = 3

#    LLMChat.MaxConversationRounds
#        Description: Maximum number of back-and-forth exchanges in a conversation
#        Default:     3  - (Three rounds of responses)
#                     0  - (Disabled)
#                     1-10  - (Number of conversation rounds)

LLMChat.MaxConversationRounds = 3

#    LLMChat.ResponseChance
#        Description: Percentage chance (0-100) that an eligible bot will respond
#        Default:     50  - (50% chance to respond)
#                     0  - (Never respond)
#                     100  - (Always respond)

LLMChat.ResponseChance = 75

################################################################################################### 